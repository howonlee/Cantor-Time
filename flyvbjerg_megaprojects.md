The definition of megaprojects is predicated on complexity. Because of the scale of them (the apocryphal quote allegedly by Stalin, Lenin, Mao, Trotsky: "quantity has a quality all its own"), they have a qualitatively different requirement for the project managers who should lead them.

They are getting radically bigger: exponentially bigger. You see individual projects that are larger than the economies of Guetamala and Honduras and things

The theory that they're talking about is dependent upon the "Sublime". Possible things to talk about it: criticality. The effects of megaprojects is construed to be complex in a way that is scale-invariant, but there you go... Could it be criticality? The guy obviously doesn't have Taleb's understanding of the criticality science and of the genesis of power laws, but does anybody, in the current state of the art? The formalisms are very beautiful but not much accepted...

Cites himself regarding the multiplicity of sublimes. Is there a unity in sublimity? Obviously phenomenological quantity, but held to be of the first importance, which is usually true. "If you wish to build a ship, don't drum up people to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."

10 grand problems with megaprojects, each interconnected, but each dense in its interconnections with the other projects, left unstate, each one only a commonality with two or one.

Exemplars of cost overrun. Not said to be a representative sample, but we see scale-invariance anyways, except in the lower percentages. Average cost overrun of 44.7, but in this case averages mean nothing: what's the average _and_ the median _and_ skew, kurtosis, etc? Actually, I would conjecture that moments of order up to infinity may matter...

What's the most risky? Software! One in six not only overruns, but becomes an outlier in terms of overrun. Delays on dams: 45% _on average_ Average means nothing!

An argument which should be brought up is Watts and Strogatz's (did they originate it?) argument about the easy promulgation of power laws in rewiring a random graph. The "fragility" of the Gaussian in this regime, and the long time coming in the reinstatement of the CLT. 10,000 times more data needed than previous!

Why is MCMC modelling here so obscure? Why don't people use the Emcee Hammer?

Flyvbjerg proposes megaproject paradox, but they should be a natural consequence, in terms of network dynamics: think of it as a densification result.

There are theories promulgated. Not particularly interested in them, because they're also correlative theories. Can't exactly spend $10 billion on a causative trial, can we? Flyvbjerg also does the criticism, this one based on too little data. But they are sort of N=1 theories, "turkey" theories... Stories, basically. Kahneman cite. What is the nature of prospect theory? Is the prospect smooth? There are instabilities...

Utzon had his career ruined by one of the most iconic piece of architecture that exists, one of the greatest cost overruns in history... Why is Gehry so good at getting shit done, though?

"Initial problems, if not dealt with up front, tend not to go away." Path dependence? Criticality or the thousand other ways to get path dependence? Actually, we just have the positive feedback, but that's basically synonymous with correlation length divergence, and the path dependence explanations map one-to-one with power law explanations. Is ontology itself predicated on such factors? Philosophy lives in the shadow of Plato...

Kahneman has the problem of the physicist (due to SMBC, hilariously). The physicist knows all about the nature of gravity itself, but still goes splat if you drop him from 10,000 feet... so it is with the psychologist and optimism bias. But what if you look at the whole thing qualitatively, with exponential (or hyperbolic) stages?
